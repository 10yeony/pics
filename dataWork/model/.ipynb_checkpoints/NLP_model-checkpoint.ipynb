{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 자연어 처리기로 데이터 셋 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 핸들링 프레임\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from pandas import DataFrame as df\n",
    "import csv\n",
    "import os\n",
    "\n",
    "# 자연어 처리기\n",
    "from konlpy.tag import Okt\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 전처리 모델\n",
    "class getDescTags:\n",
    "    def __init__(self,n,dataset):\n",
    "        self.n=n\n",
    "        self.dataset = dataset\n",
    "\n",
    "    # 1) description 다듬기 : 데이터 정규화, 맥락 위주로 자르고 명사만 가져오기, 글자길이는 1 ~ 7  \n",
    "    def getDescList(self,n,dataset):\n",
    "        self.n=n\n",
    "        okt=Okt()\n",
    "        descList=[]\n",
    "        for i in range(n):\n",
    "            tempList=[]\n",
    "            descript=(dataset.description[i]) # 한글자 이상만 뽑음\n",
    "            descript=descript.replace(\"\\n\",\"\")\n",
    "            descript=descript.replace(\"\\r\",\"\")\n",
    "            descript=descript.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣AZ09]\",\"\")\n",
    "            tempList=[j[0] for j in okt.pos(descript) if ((len(j[0])>1)& (len(j[0])<7)& (j[1]==\"Noun\"))]\n",
    "            tempList=list(set(tempList))\n",
    "            if len(tempList)>0:\n",
    "                descList.append(tempList)\n",
    "            else:\n",
    "                descList.append(tempList)\n",
    "        return descList\n",
    "    \n",
    "    ## 2) Tag 다듬기 : 복합명사로 이루어진 태그는 잘라서 길이 2~7 사이의 단어만 추출\n",
    "    def getTagList(self,dataset):\n",
    "        n=len(dataset)\n",
    "        parseTagList=[]\n",
    "        okt=Okt()\n",
    "        for i in range(n):\n",
    "            tempTagList=[]\n",
    "            tags=str(dataset.tag[i]).split('#') # 태그별로 자르기\n",
    "            for tag in tags:\n",
    "                if len(tag)>1:\n",
    "                    okt.pos(tag)  # 1개 태그 내 복합 명사 자르기\n",
    "                    for j in okt.nouns(tag):\n",
    "                        if(len(j)>=2|len(j)<7):\n",
    "                            tempTagList.append(j)\n",
    "            tempTagList=list(set(tempTagList))\n",
    "            parseTagList.append(tempTagList)\n",
    "        return parseTagList\n",
    "\n",
    "    \n",
    "    ## 3-1) 코어 태그 추출 (태그, description 합집합)\n",
    "    def getCoreTags1(self,dataset):\n",
    "        n=len(dataset)\n",
    "        coreTagList1=[]\n",
    "        okt=Okt()    \n",
    "        coreTag=[]\n",
    "        descript=getDescList(dataset) # 한글자 이상만 뽑음\n",
    "        tags=getTagList(dataset)  # tag를 한번 더 파싱\n",
    "        for i in range(len(descript)): \n",
    "            if (len(tags[i])>0): \n",
    "                coreTag.append(tags[i]+descript[i])\n",
    "            else:\n",
    "                coreTag.append(descript[i])\n",
    "        coreTagList1.append(coreTag)\n",
    "        CoreTagData1=getCoreTags1(len(dataset))\n",
    "        CoreTagData1=CoreTagData1[0]\n",
    "        return CoreTagData1\n",
    "    \n",
    "    \n",
    "    ## 3-2) 코어 태그 추출 (부분적으로 기존 태그 + description + coreTag )\n",
    "    def getCoreTags2(self,dataset):\n",
    "        n=len(dataset)\n",
    "        coreTagList=[]\n",
    "        okt=Okt()    \n",
    "        descript=getDescList(dataset) # 한글자 이상만 뽑음\n",
    "        tags=getTagList(dataset)  # tag를 한번 더 파싱\n",
    "        for k in range(len(descript)):\n",
    "            coreTags=[]\n",
    "            for t in range(len(tags[k])):\n",
    "                if (len(tags[k][t])>0)&(tags[k][t] in descript[k]): # 태그가 description 단어에도 있는지 확인\n",
    "                    coreTags.append(tags[k][t])\n",
    "            if (len(tags[k])<=3): # 태그 수가 없으면 디스크립션으로\n",
    "                coreTagList.append(list(set(descript[k])))\n",
    "            elif((len(coreTags)<=3)&(len(tags[k])>3)):# desc와 일치하는 태그(coreTag)가 적은데 기존 태그(tags[k])많으면 기존 태그 사용\n",
    "                coreTagList.append(tags[k])\n",
    "            elif(len(coreTags)>3): # 디스크립션과 일치하는 태그가 많으면 일치태그 사용\n",
    "                coreTagList.append(coreTags)\n",
    "            else:\n",
    "                coreTagList.append(list(set(descript[k]))) \n",
    "        return coreTagList\n",
    "\n",
    "    \n",
    "    # Tag2 데이터 보정 : Tag1의 데이터 갖다쓰기\n",
    "    def fillCoreTag(self,CoreTagData1,CoreTagData2):\n",
    "        for i in range(len(CoreTagData2)):\n",
    "            if len(CoreTagData2[i])<1:\n",
    "                CoreTagData2[i]=(CoreTagData1[i])\n",
    "\n",
    "        for i in range(len(CoreTagDate2)):\n",
    "            CoreTagData2[i]=list(set(CoreTagData2[i]))\n",
    "            CoreTagData1[i]=list(set(CoreTagData1[i]))\n",
    "        return CoreTagData2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook nlp_model.ipynb to script\n",
      "[NbConvertApp] Writing 3714 bytes to nlp_model.py\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert --to script nlp_model.ipynb "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
